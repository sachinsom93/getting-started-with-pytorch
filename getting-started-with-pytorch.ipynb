{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# What is PyTorch?\n",
    "* Its a machine learning library used for NLP, computer vision,etc.\n",
    "* Provides Tensor computing with GPU support.\n",
    "\n",
    "# Modules in Pytorch\n",
    "*  **Autograd module:**\n",
    "PyTorch uses a method called automatic differentiation. A recorder records what operations have performed, and then it replays it backward to compute the gradients. This method is especially powerful when building neural networks to save time on one epoch by calculating differentiation of the parameters at the forward pass.\n",
    "\n",
    "* **Optim module:**\n",
    "torch.optim is a module that implements various optimization algorithms used for building neural networks. \n",
    "\n",
    "* **nn module:**\n",
    "PyTorch autograd makes it easy to define computational graphs and take gradients, but raw autograd can be a bit too low-level for defining complex neural networks. This is where the nn module can help.\n",
    "\n",
    "# Topics covered in this notebook\n",
    "* Handwritten Digits Classification (Numerical Data)-**Digit MNIST**\n",
    "* Objects Image Classification (Image Data, CNN)-**Sign Language MNIST**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Handwritten Digits Classification (Numerical Data)-Digit MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Importing lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import math\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "#pytorch utility imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "#neural net imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True) #time measure during cuda training\n",
    "end = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Importing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../input/mnist-in-csv/mnist_test.csv')\n",
    "train_df = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Separating labels and features (pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df['label'].values # converting to numpy also\n",
    "\n",
    "test_labels=test_df['label'].values\n",
    "train_images = (train_df.iloc[:,1:].values).astype('float32')\n",
    "test_images = (test_df.iloc[:,1:].values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape (60000, 784)\n",
      "train labels shape (60000,)\n",
      "test images shape (10000, 784)\n",
      "test labels shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train images shape\",train_images.shape)\n",
    "print(\"train labels shape\",train_labels.shape)\n",
    "print(\"test images shape\",test_images.shape)\n",
    "print(\"test labels shape\",test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Reshape features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Visualize some training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train samples\n",
    "for i in range(6, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(train_images[i].squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.title(train_labels[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Convert numpy data into tensor for PyTorch\n",
    "* torch.tensor default uses float\n",
    "* feature are divided by 255 to change them into suitable range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_tensor = torch.tensor(train_images)/255.0 #default torch.FloatTensor\n",
    "train_labels_tensor = torch.tensor(train_labels)\n",
    "train_tensor = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "\n",
    "test_images_tensor = torch.tensor(test_images)/255.0\n",
    "test_labels_tensor = torch.tensor(test_labels)\n",
    "test_tensor = TensorDataset(test_images_tensor, test_labels_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### DataLoader for train and test \n",
    "* Batch size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_tensor, batch_size=16, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_images_tensor, batch_size=16, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 548)\n",
    "        self.bc1 = nn.BatchNorm1d(548)\n",
    "        \n",
    "        self.fc2 = nn.Linear(548, 252)\n",
    "        self.bc2 = nn.BatchNorm1d(252)\n",
    "        \n",
    "        self.fc3 = nn.Linear(252, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, 784))\n",
    "        h = self.fc1(x)\n",
    "        h = self.bc1(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        \n",
    "        h = self.fc2(h)\n",
    "        h = self.bc2(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=0.2, training=self.training)\n",
    "        \n",
    "        h = self.fc3(h)\n",
    "        out = F.log_softmax(h)\n",
    "        return out\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Checking for cuda availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "if (device.type=='cuda'):\n",
    "    model.cuda() # convert model to cuda model\n",
    "\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #adam optimizer from optim module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 0 [59984/60000 (100%)]\tLoss: 0.078582\n",
      " Train Epoch: 1 [59984/60000 (100%)]\tLoss: 0.329871\n",
      " Train Epoch: 2 [59984/60000 (100%)]\tLoss: 0.155539\n",
      " Train Epoch: 3 [59984/60000 (100%)]\tLoss: 0.013120\n",
      " Train Epoch: 4 [59984/60000 (100%)]\tLoss: 0.226431\n",
      " Train Epoch: 5 [59984/60000 (100%)]\tLoss: 0.153548\n",
      " Train Epoch: 6 [59984/60000 (100%)]\tLoss: 0.013032\n",
      " Train Epoch: 7 [59984/60000 (100%)]\tLoss: 0.005125\n",
      " Train Epoch: 8 [59984/60000 (100%)]\tLoss: 0.035286\n",
      " Train Epoch: 9 [59984/60000 (100%)]\tLoss: 0.111835\n",
      " Train Epoch: 10 [59984/60000 (100%)]\tLoss: 0.324415\n",
      " Train Epoch: 11 [59984/60000 (100%)]\tLoss: 0.124107\n",
      " Train Epoch: 12 [59984/60000 (100%)]\tLoss: 0.158513\n",
      " Train Epoch: 13 [59984/60000 (100%)]\tLoss: 0.042156\n",
      " Train Epoch: 14 [59984/60000 (100%)]\tLoss: 0.023657\n",
      " Train Epoch: 15 [59984/60000 (100%)]\tLoss: 0.019556\n",
      " Train Epoch: 16 [59984/60000 (100%)]\tLoss: 0.027390\n",
      " Train Epoch: 17 [59984/60000 (100%)]\tLoss: 0.140433\n",
      " Train Epoch: 18 [59984/60000 (100%)]\tLoss: 0.006098\n",
      " Train Epoch: 19 [7536/60000 (13%)]\tLoss: 0.039932"
     ]
    }
   ],
   "source": [
    "if (device.type=='cuda'):\n",
    "    start.record() #timer start\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "losses = []\n",
    "for epoch in range(20):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Get Samples\n",
    "        if (device.type=='cuda'):\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target) # making group of 16\n",
    "            \n",
    "        \n",
    "        # Init\n",
    "        optimizer.zero_grad() #making gradient zero for new mini-batch. \n",
    "\n",
    "        # Predict\n",
    "        y_pred = model(data) \n",
    "         \n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(y_pred, target)\n",
    "        losses.append(loss.data)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()  #It computes gradient of loss w.r.t all the parameters and store them in (parameter.grad) attribute.\n",
    "        optimizer.step() #optimizer.step() updates all the parameters based on (parameter.grad)\n",
    "        \n",
    "        \n",
    "        # Display\n",
    "        #if batch_idx % 100 == 1:\n",
    "        print('\\r Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format( epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data), end='')\n",
    "            \n",
    "    print()\n",
    "    \n",
    "if (device.type=='cuda'):\n",
    "    end.record()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Predicting the output and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "if (device.type=='cuda'):\n",
    "    evaluate_x=test_images_tensor.cuda()\n",
    "    evaluate_y=test_labels_tensor.cuda()\n",
    "else:\n",
    "    evaluate_x=test_images_tensor\n",
    "    evaluate_y=test_labels_tensor\n",
    "    \n",
    "\n",
    "output = model(evaluate_x)\n",
    "\n",
    "pred = output.data.max(1)[1]\n",
    "d = pred.eq(evaluate_y.data).cpu()\n",
    "a=(d.sum().data.cpu().numpy())\n",
    "b=d.size()\n",
    "b=torch.tensor(b)\n",
    "b=(b.sum().data.cpu().numpy())\n",
    "accuracy = a/b\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    " ### Time used for training if cuda is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415.8584375 sec\n"
     ]
    }
   ],
   "source": [
    "if (device.type=='cuda'):\n",
    "    torch.cuda.synchronize()\n",
    "    print(start.elapsed_time(end)/1000,\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Objects Image Classification (Image Data, CNN)-Sign Language MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv')\n",
    "train_df = pd.read_csv('../input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24,)\n",
      "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "print((train_df['label'].unique()).shape )# There are 24 possible labels, 9=J and 25=Z require motion so they are absent.\n",
    "print(np.sort(train_df['label'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Separating labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df['label'].values\n",
    "test_labels=test_df['label'].values\n",
    "train_images = (train_df.iloc[:,1:].values).astype('float32')\n",
    "test_images = (test_df.iloc[:,1:].values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape (27455, 784)\n",
      "train labels shape (27455,)\n",
      "test images shape (7172, 784)\n",
      "test labels shape (7172,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train images shape\",train_images.shape)\n",
    "print(\"train labels shape\",train_labels.shape)\n",
    "print(\"test images shape\",test_images.shape)\n",
    "print(\"test labels shape\",test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Reshape features\n",
    "*Note: For images reshape will be in 4D*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0],1, 28, 28)\n",
    "test_images = test_images.reshape(test_images.shape[0],1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 1, 28, 28)\n",
      "(7172, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Changing to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_tensor = torch.tensor(train_images)/255.0 #default torch.FloatTensor\n",
    "train_labels_tensor = torch.tensor(train_labels)\n",
    "train_tensor = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "\n",
    "test_images_tensor = torch.tensor(test_images)/255.0\n",
    "test_labels_tensor = torch.tensor(test_labels)\n",
    "test_tensor = TensorDataset(test_images_tensor, test_labels_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_tensor, batch_size=16, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_images_tensor, batch_size=16, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "class Net(nn.Module):                                           # class Net inherits from predefined Module class in torch.nn\n",
    "    def __init__(self):                                         # calling constructor of  parent class\n",
    "        super().__init__()                                     \n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,32,3)              # 2d convolution layer : (input : 1 image , output : 32 channels , kernel size : 3*3)\n",
    "        self.conv2 = nn.Conv2d(32,64,3)\n",
    "        self.conv3 = nn.Conv2d(64,128,3)\n",
    "        \n",
    "        self.linear_in = None                      # used to calculate input of first linear layer by passing fake data through 2d layers\n",
    "        x = torch.rand(28,28).view(-1,1,28,28)     # using convs function\n",
    "        self.convs(x)\n",
    "    \n",
    "        self.fc1 = nn.Linear(self.linear_in,512)\n",
    "        self.fc2 = nn.Linear(512,26)\n",
    "        \n",
    "    def convs(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)) , (2,2) )      # relu used for activation function \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)) , (2,2) )      # max_pool2d for max pooling results of each kernel with window size 2*2\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)) , (2,2) )\n",
    "        \n",
    "        if self.linear_in == None:\n",
    "            self.linear_in = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]  # input of first linear layer is multiplication of dimensions of ouput \n",
    "        return x                                                        # tensor of the 2d layers\n",
    "    \n",
    "    def forward(self,x):                                    # forward pass function uses the convs function to pass through 2d layers\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1,self.linear_in)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x ,dim = -1)                     # log_softmax for finding output neuron with highest value\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=26, bias=True)\n",
      ")\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(net)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "if (device.type=='cuda'):\n",
    "    model.cuda() # CUDA\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 0 [25725/27455 (100%)] \tLoss: 0.208132\n",
      " Train Epoch: 1 [25725/27455 (100%)] \tLoss: 0.005389\n",
      " Train Epoch: 2 [25725/27455 (100%)] \tLoss: 0.022597\n",
      " Train Epoch: 3 [25725/27455 (100%)] \tLoss: 0.000477\n",
      " Train Epoch: 4 [25725/27455 (100%)] \tLoss: 0.000133\n",
      " Train Epoch: 5 [25725/27455 (100%)] \tLoss: 0.000060\n",
      " Train Epoch: 6 [25725/27455 (100%)] \tLoss: 0.004529\n",
      " Train Epoch: 7 [25725/27455 (100%)] \tLoss: 0.002645\n",
      " Train Epoch: 8 [25725/27455 (100%)] \tLoss: 0.000051\n",
      " Train Epoch: 9 [25725/27455 (100%)] \tLoss: 0.000004\n",
      " Train Epoch: 10 [25725/27455 (100%)] \tLoss: 0.000001\n",
      " Train Epoch: 11 [25725/27455 (100%)] \tLoss: 0.005079\n",
      " Train Epoch: 12 [25725/27455 (100%)] \tLoss: 0.000011\n",
      " Train Epoch: 13 [25725/27455 (100%)] \tLoss: 0.000001\n",
      " Train Epoch: 14 [25725/27455 (100%)] \tLoss: 0.000003\n",
      " Train Epoch: 15 [25725/27455 (100%)] \tLoss: 0.000009\n",
      " Train Epoch: 16 [25725/27455 (100%)] \tLoss: 0.000000\n",
      " Train Epoch: 17 [25725/27455 (100%)] \tLoss: 0.000197\n",
      " Train Epoch: 18 [25725/27455 (100%)] \tLoss: 0.000031\n",
      " Train Epoch: 19 [25725/27455 (100%)] \tLoss: 0.000070\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if (device.type=='cuda'):\n",
    "    start.record() \n",
    "    \n",
    "loss_log = []\n",
    "for epoch in range(20): # loop over dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, (data,target) in enumerate(train_loader):\n",
    "\n",
    "        \n",
    "        if (device.type=='cuda'):\n",
    "            inputs,labels= Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            inputs,labels= Variable(data), Variable(target)\n",
    "       \n",
    "        \n",
    "        \n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss =  F.cross_entropy(outputs, labels)\n",
    "        #print(loss)\n",
    "        \n",
    "   \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "      \n",
    "        #if i % 100 == 1:\n",
    "        print('\\r Train Epoch: {} [{}/{} ({:.0f}%)] \\tLoss: {:.6f}'.format( epoch, i * len(data), len(train_loader.dataset),\n",
    "                                                                           100. * i / len(train_loader), loss.data), end='')\n",
    "        \n",
    "    print(\"\")\n",
    "                \n",
    "print('Finished Training')\n",
    "if (device.type=='cuda'):\n",
    "    end.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.25153374233128\n"
     ]
    }
   ],
   "source": [
    "if (device.type=='cuda'):\n",
    "    evaluate_x=test_images_tensor.cuda()\n",
    "    evaluate_y=test_labels_tensor.cuda()\n",
    "else:\n",
    "    evaluate_x=test_images_tensor\n",
    "    evaluate_y=test_labels_tensor\n",
    "    \n",
    "\n",
    "output = net(evaluate_x)\n",
    "\n",
    "pred = output.data.max(1)[1]\n",
    "d = pred.eq(evaluate_y.data).cpu()\n",
    "a=(d.sum().data.cpu().numpy())\n",
    "b=d.size()\n",
    "b=torch.tensor(b)\n",
    "b=(b.sum().data.cpu().numpy())\n",
    "accuracy = a/b\n",
    "\n",
    "print('Accuracy:', accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.3401875 sec\n"
     ]
    }
   ],
   "source": [
    "if (device.type=='cuda'):\n",
    "    torch.cuda.synchronize()\n",
    "    print(start.elapsed_time(end)/1000,\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Calculating the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score = 0.9268968946741317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"f1 score =\",f1_score(test_labels, pred.cpu().numpy(), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Other use case to be covered in upcoming notebook\n",
    "\n",
    "* R-CNN\n",
    "* Sentiment Text Classification (Text Data, RNN)\n",
    "* Image Style Transfer (Transfer Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Lets get connected on [Linkedin](https://www.linkedin.com/in/manzoor-bin-mahmood/)\n",
    "\n",
    "Visit my [website](https://manzoormahmood.github.io/) \n",
    "\n",
    "### Please **upvote** my work if you like it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
